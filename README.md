# VNPT Hackathon 2025

## Pipeline Flow (predict.py)
![Workflow](img/workflow.jpg)

H·ªá th·ªëng ch√∫ng t√¥i s·ª≠ d·ª•ng ki·∫øn tr√∫c **Adaptive Pipeline** th√¥ng minh, t·ª± ƒë·ªông ƒëi·ªÅu h∆∞·ªõng c√¢u h·ªèi ƒë·∫øn quy tr√¨nh x·ª≠ l√Ω t·ªëi ∆∞u nh·∫•t thay v√¨ √°p d·ª•ng RAG r·∫≠p khu√¥n cho m·ªçi tr∆∞·ªùng h·ª£p.

### 1. Question Classification (Adaptive Routing)
M·ªçi Query ƒë·∫ßu v√†o (Question + Choices) ƒë∆∞·ª£c **LLM Small** ph√¢n lo·∫°i th√†nh 4 nh√≥m chi·∫øn l∆∞·ª£c:

*   **üõ°Ô∏è Safety & Policy Filter (`cannot_answer`)**:
    *   Nh·∫≠n di·ªán c√°c c√¢u h·ªèi nh·∫°y c·∫£m, vi ph·∫°m ch√≠nh s√°ch ho·∫∑c ƒë·ªôc h·∫°i.
    *   **H√†nh ƒë·ªông**: H·ªá th·ªëng l·∫≠p t·ª©c ch·ªçn ƒë√°p √°n t·ª´ ch·ªëi (v√≠ d·ª•: "T√¥i kh√¥ng th·ªÉ tr·∫£ l·ªùi...") m√† kh√¥ng c·∫ßn x·ª≠ l√Ω th√™m, ƒë·∫£m b·∫£o an to√†n tuy·ªát ƒë·ªëi.

*   **üßÆ Advanced STEM Reasoning (`calculation`)**:
    *   D√†nh cho c√°c c√¢u h·ªèi To√°n, L√Ω, H√≥a c·∫ßn t√≠nh to√°n ch√≠nh x√°c.
    *   **M√¥ h√¨nh "Expert-Auditor"**:
        1.  **Stage 1 (The Expert - LLM Large)**: Ph√¢n t√≠ch b√†i to√°n, thi·∫øt l·∫≠p c√¥ng th·ª©c v√† gi·∫£i chi ti·∫øt t·ª´ng b∆∞·ªõc.
        2.  **Stage 2 (The Auditor - LLM Large)**: ƒê√≥ng vai tr√≤ ki·ªÉm to√°n vi√™n, ki·ªÉm tra l·∫°i logic v√† t√≠nh to√°n c·ªßa chuy√™n gia ƒë·ªÉ ƒë·∫£m b·∫£o kh√¥ng c√≥ l·ªói "·∫£o gi√°c" s·ªë h·ªçc, sau ƒë√≥ m·ªõi ch·ªët ƒë√°p √°n cu·ªëi c√πng.

*   **üìñ Context-Aware Reading (`has_context`)**:
    *   D√†nh cho c√°c c√¢u h·ªèi ƒë·ªçc hi·ªÉu ƒë√£ c√≥ s·∫µn ƒëo·∫°n vƒÉn b·∫£n d√†i trong ƒë·ªÅ b√†i.
    *   S·ª≠ d·ª•ng **LLM Large** v·ªõi prompt chuy√™n bi·ªát cho k·ªπ nƒÉng ƒë·ªçc hi·ªÉu, t·∫≠p trung khai th√°c d·ªØ ki·ªán n·ªôi t·∫°i m√† kh√¥ng k√≠ch ho·∫°t RAG ƒë·ªÉ tr√°nh nhi·ªÖu th√¥ng tin b√™n ngo√†i.

*   **üåê Adaptive RAG (`general`)**:
    *   D√†nh cho c√°c c√¢u h·ªèi ki·∫øn th·ª©c chung c·∫ßn tra c·ª©u th√¥ng tin b√™n ngo√†i.
    *   **Quy tr√¨nh RAG n√¢ng cao**:
        1.  **Query Expansion**: Gh√©p `Question + Choices` ƒë·ªÉ tƒÉng ng·ªØ c·∫£nh t√¨m ki·∫øm.
        2.  **Hybrid Search**: K·∫øt h·ª£p **Dense Embedding** (VNPT API) v√† **Sparse Embedding** (BM25) tr√™n Qdrant, s·ª≠ d·ª•ng thu·∫≠t to√°n **Reciprocal Rank Fusion (RRF)** ƒë·ªÉ l·∫•y Top 30 t√†i li·ªáu ti·ªÅm nƒÉng.
        3.  **LLM-as-a-Judge Reranking**: Thay v√¨ d√πng Cross-Encoder th√¥ng th∆∞·ªùng, h·ªá th·ªëng s·ª≠ d·ª•ng **LLM Small** ƒë·ªÉ "ch·∫•m ƒëi·ªÉm" 30 t√†i li·ªáu theo 4 ti√™u ch√≠: *ƒê√∫ng ch·ªß ƒë·ªÅ, C√≥ t·ª´ kh√≥a, Th√¥ng tin h·ªØu √≠ch, v√† T√≠nh c·∫≠p nh·∫≠t (Freshness)*.
        4.  **Filtering**: Ch·ªâ gi·ªØ l·∫°i t·ªëi ƒëa **Top 5** t√†i li·ªáu c√≥ ƒëi·ªÉm s·ªë > 7.0.
        5.  **Final Answer**: **LLM Large** t·ªïng h·ª£p th√¥ng tin t·ª´ c√°c t√†i li·ªáu ch·∫•t l∆∞·ª£ng cao n√†y ƒë·ªÉ ƒë∆∞a ra c√¢u tr·∫£ l·ªùi cu·ªëi c√πng.

> **Note**: Vi·ªác s·ª≠ d·ª•ng `LLM Small` l√†m Reranker cho ph√©p x·ª≠ l√Ω Context Window l·ªõn h∆°n (ƒë√°nh gi√° ƒë∆∞·ª£c 30 t√†i li·ªáu c√πng l√∫c) v√† linh ho·∫°t h∆°n trong vi·ªác ƒë√°nh gi√° "t√≠nh c·∫≠p nh·∫≠t" c·ªßa th√¥ng tin so v·ªõi c√°c m√¥ h√¨nh Rerank truy·ªÅn th·ªëng. T·∫•t c·∫£ LLMs ƒë·ªÅu s·ª≠ d·ª•ng `temperature  = 0` ƒë·ªÉ tr√°nh b·ªã Hallucinations.

## Data Processing
- C√°c ngu·ªìn d·ªØ li·ªáu v√† c√°ch x·ª≠ l√Ω ƒë∆∞·ª£c ƒë·ªÉ ·ªü link: [sheet](https://docs.google.com/spreadsheets/d/176Hs2OUBhQj6UrNkRyu4dse9xK_ag_6VMZZsd2maLy8/edit?usp=sharing)
- T·ªïng h·ª£p d·ªØ li·ªáu ƒë∆∞·ª£c ƒë·ªÉ ·ªü link: [Data](https://drive.google.com/drive/folders/1dUnodqUE3Ea0ESjACpEEGARFgtiua-KR?usp=sharing). Trong ƒë√≥, folder `input` ch·ª©a c√°c file ƒë√£ ƒë∆∞·ª£c crawl xong, folder `output` ch·ª©a c√°c file ƒë∆∞·ª£c ƒë∆∞a v·ªÅ d·∫°ng `.csv`.
- Data ƒë∆∞·ª£c crawl t·ª´ nhi·ªÅu ngu·ªìn kh√°c nhau. Sau khi crawl, data ƒë∆∞·ª£c g·ªôp l·∫°i th√†nh 1 file .csv c√≥ 3 c·ªôt "id", "title" v√† "text". Trong ƒë√≥, c·ªôt "id" v√† "title" kh√¥ng quan tr·ªçng, c·ªôt "text" ƒë√≥ng g√≥p tr·ª±c ti·∫øp v√¥ vector database.
- Cu·ªëi c√πng, g·ªôp t·∫•t c·∫£ l·∫°i th√†nh 1 file `vectorDB/data/data.csv` duy nh·∫•t.

## Vector Database work flow (High-Performance Indexing)

Ch√∫ng t√¥i ƒë√£ x√¢y d·ª±ng m·ªôt quy tr√¨nh **Asynchronous Indexing Pipeline** (`vectorDB/main_async.py`) ƒë∆∞·ª£c t·ªëi ∆∞u h√≥a cao ƒë·ªô ƒë·ªÉ x·ª≠ l√Ω l∆∞·ª£ng d·ªØ li·ªáu l·ªõn m·ªôt c√°ch nhanh ch√≥ng v√† b·ªÅn b·ªâ:

1.  **Hybrid Search Architecture**:
    *   K·∫øt h·ª£p s·ª©c m·∫°nh c·ªßa **Dense Embedding** (VNPT AI API, 1024 dim) ƒë·ªÉ b·∫Øt ng·ªØ nghƒ©a v√† **Sparse Embedding** (FastEmbed BM25) ƒë·ªÉ b·∫Øt t·ª´ kh√≥a ch√≠nh x√°c.
    *   C·∫•u h√¨nh Qdrant collection v·ªõi c·∫£ `vectors_config` (Cosine) v√† `sparse_vectors_config` (IDF), t·∫°o ti·ªÅn ƒë·ªÅ cho thu·∫≠t to√°n Hybrid Search ch√≠nh x√°c cao.

2.  **Parallel Async Processing (S√°ng t·∫°o & T·ªëi ∆∞u)**:
    *   Thay v√¨ ch·∫°y tu·∫ßn t·ª±, h·ªá th·ªëng s·ª≠ d·ª•ng `asyncio` ƒë·ªÉ th·ª±c hi·ªán song song hai t√°c v·ª• n·∫∑ng nh·∫•t: **G·ªçi API Embedding** v√† **T√≠nh to√°n BM25** c√πng l√∫c (`asyncio.gather`).
    *   TƒÉng t·ªëc ƒë·ªô x·ª≠ l√Ω l√™n g·∫•p **5-8 l·∫ßn** so v·ªõi phi√™n b·∫£n synchronous truy·ªÅn th·ªëng.

3.  **Robust API Rate Limiting & Resilience**:
    *   Thi·∫øt k·∫ø c∆° ch·∫ø **Semaphore** ƒë·ªÉ ki·ªÉm so√°t ch·∫∑t ch·∫Ω s·ªë l∆∞·ª£ng request ƒë·ªìng th·ªùi (`MAX_CONCURRENT_REQUESTS`), ƒë·∫£m b·∫£o kh√¥ng bao gi·ªù v∆∞·ª£t qu√° gi·ªõi h·∫°n 500 req/ph√∫t c·ªßa VNPT API.
    *   T√≠ch h·ª£p c∆° ch·∫ø **Exponential Backoff** th√¥ng minh: t·ª± ƒë·ªông ch·ªù v√† th·ª≠ l·∫°i khi g·∫∑p l·ªói m·∫°ng ho·∫∑c 429 Too Many Requests.
    *   **Note**: Khi ch·∫°y l·∫°i t·ª´ ƒë·∫ßu c√≥ th·ªÉ comment c√°c d√≤ng `.sleep` ƒë·ªÉ ch·∫°y nhanh h∆°n

4.  **Smart Resume & Deduplication**:
    *   H·ªá th·ªëng t·ª± ƒë·ªông qu√©t c√°c Point ID ƒë√£ t·ªìn t·∫°i trong Qdrant tr∆∞·ªõc khi ch·∫°y.
    *   Cho ph√©p t·∫°m d·ª´ng v√† ti·∫øp t·ª•c (Resume) qu√° tr√¨nh ƒë√°nh index b·∫•t c·ª© l√∫c n√†o m√† kh√¥ng c·∫ßn ch·∫°y l·∫°i t·ª´ ƒë·∫ßu, ti·∫øt ki·ªám chi ph√≠ API v√† th·ªùi gian.

5.  **Context-Aware Chunking**:
    *   S·ª≠ d·ª•ng `SentenceSplitter` c·ªßa Llama-index ƒë·ªÉ c·∫Øt vƒÉn b·∫£n theo ng·ªØ nghƒ©a c√¢u (`chunk_size=512`, `overlap=32`), tr√°nh vi·ªác c·∫Øt gi·ªØa ch·ª´ng l√†m m·∫•t ng·ªØ c·∫£nh.

**C·∫•u tr√∫c d·ªØ li·ªáu l∆∞u tr·ªØ (Payload):**
```json
{
  "id": "point_id (generated sequentially)",
  "vector": {
    "dense": [0.01, -0.02, ...], // VNPT Embedding
    "sparse": {
      "indices": [12, 50, ...],   // BM25 Indices
      "values": [0.5, 0.8, ...]   // BM25 Values
    }
  },
  "payload": {
    "doc_id": "Original Document ID",
    "title": "Document Title",
    "chunk_index": "Index of chunk in document",
    "text": "Full text content of the chunk"
  }
}
```

## Resource Initialization
### API Keys Configuration
The `api-keys.json` file contains API credentials for VNPT AI Services:

```json
[
  {
    "authorization": "Bearer <JWT_TOKEN>",
    "tokenKey": "<PUBLIC_KEY_BASE64>",
    "llmApiName": "<MODEL_NAME>",
    "tokenId": "<TOKEN_UUID>"
  }
]
```

| Field | Description |
|-------|-------------|
| `authorization` | JWT Bearer token for API authentication |
| `tokenKey` | RSA public key (Base64) for encryption |
| `llmApiName` | Model name: `LLM large`, `LLM small`, or `LLM embedings` |
| `tokenId` | Token UUID identifier |

> **Note:** Configure `api-keys.json` with valid credentials before running `predict.py` and `vectorDB/main_async.py`. This file is in the main folder.

### How to run
1. Download file `data.csv` in `data.zip` at this [drive](https://drive.google.com/drive/folders/1dUnodqUE3Ea0ESjACpEEGARFgtiua-KR?usp=sharing). Put it in folder `/vectorDB/data`
2. Install Dependencies!
```
pip install -r requirements.txt
```
3. Run the Qdrant vector database workflow:
```
cd vectorDB
python main_async.py
```
4. Ensure file `test.json` is in folder `data`. Run the workflow pipeline:
```
python main.py
```
5. `submission.csv` and `predict.json` is in folder `output`
